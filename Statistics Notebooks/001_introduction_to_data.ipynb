{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Types of variables (Page 15 - Section 1.2.2)\n",
    "\n",
    "You have learned about continuous (numerical), discrete (numerical), nominal (categorical), and ordinal (categorical) variable types. Let's see an example dataframe with each type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Number_of_Children</th>\n",
       "      <th>Favorite_Color</th>\n",
       "      <th>Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182.3</td>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158.4</td>\n",
       "      <td>3</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.2</td>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height_cm  Number_of_Children Favorite_Color Satisfaction\n",
       "0      175.0                   2            Red         High\n",
       "1      160.5                   1           Blue          Low\n",
       "2      182.3                   0          Green       Medium\n",
       "3      158.4                   3           Blue       Medium\n",
       "4      170.2                   1          Green         High"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Height_cm': [175.0, 160.5, 182.3, 158.4, 170.2], # Continuous\n",
    "    'Number_of_Children': [2, 1, 0, 3, 1], # Discrete\n",
    "    'Favorite_Color': ['Red', 'Blue', 'Green', 'Blue', 'Green'], # Nominal\n",
    "    'Satisfaction': ['High', 'Low', 'Medium', 'Medium', 'High'] # Ordinal\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you would like to use these as features for an ML model. ML models typically expect numerical data. Therefore while numerical variables can be used as is, categorical variables might require encoding. Let's see how you can encode nominal and ordinal variables in scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Encoding nominal categorical variables\n",
    "\n",
    "The most common way to encode nominal categorical variables is One-Hot Encoding. It used to represent categorical variables as binary vectors. In this technique, each category in the variable is converted into a unique binary vector, where all elements are 0 except for the one corresponding to the category, which is set to 1. This approach is commonly used in machine learning to allow algorithms to process categorical data that would otherwise be difficult to interpret. In our example, \"Red,\" \"Blue,\" and \"Green,\" one-hot encoding would represent these as [1, 0, 0], [0, 1, 0], and [0, 0, 1], respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse_output=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The fit operation determines the encoding for each unique category in the column.\n",
    "# It sets up the encoder but does not transform the actual data yet.\n",
    "ohe.fit(df[['Favorite_Color']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Blue', 'Green', 'Red'], dtype=object)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ohe.categories_\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The transform operation converts the original categorical data\n",
    "# into one-hot encoded binary vectors.\n",
    "encoded_features = ohe.transform(df[['Favorite_Color']])\n",
    "encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Blue Green Red\n",
       "0    0     0   1\n",
       "1    1     0   0\n",
       "2    0     1   0\n",
       "3    1     0   0\n",
       "4    0     1   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The resulting features\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=feature_names).astype('int')\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please read the [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) documentation for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Encoding ordinal categorical variables\n",
    "\n",
    "Ordinal categorical variables have a meaningful order or ranking among categories. To encode these variables, one-hot encoding can be used. However, one-hot encoding loses the inherent order among the categories. Ordinal encoding, on the other hand, preserves this order by assigning integer values to each category based on their rank. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OrdinalEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit(df[['Satisfaction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = oe.transform(df[['Satisfaction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Satisfaction_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Satisfaction  Satisfaction_Encoded\n",
       "0         High                     0\n",
       "1          Low                     1\n",
       "2       Medium                     2\n",
       "3       Medium                     2\n",
       "4         High                     0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df = pd.DataFrame(encoded_features, columns=['Satisfaction_Encoded']).astype('int')\n",
    "combined_df = pd.concat([df[['Satisfaction']], encoded_df], axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal encoding indeed assigned integers to each category, however, the order is not what we expected. Without specifying the order, the encoder might assign integers based on the order in which it encounters the categories. To ensure the correct order is preserved, we can explicitly define the category order when creating the OrdinalEncoder object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OrdinalEncoder(categories=[[&#x27;Low&#x27;, &#x27;Medium&#x27;, &#x27;High&#x27;]])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[[&#x27;Low&#x27;, &#x27;Medium&#x27;, &#x27;High&#x27;]])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OrdinalEncoder(categories=[['Low', 'Medium', 'High']])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])\n",
    "oe.fit(df[['Satisfaction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Satisfaction_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Satisfaction  Satisfaction_Encoded\n",
       "0         High                     2\n",
       "1          Low                     0\n",
       "2       Medium                     1\n",
       "3       Medium                     1\n",
       "4         High                     2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_features = oe.transform(df[['Satisfaction']])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=['Satisfaction_Encoded']).astype('int')\n",
    "combined_df = pd.concat([df[['Satisfaction']], encoded_df], axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better! Please read the [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) documentation for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT\n",
    "\n",
    "The way you encode your data also depends on the algorithm you would like to use. For example CatBoost supports categorical features natively.\n",
    "\n",
    "https://catboost.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Iris Dataset (Page 20 - Exercise 1.9)\n",
    "\n",
    "Sir Ronald Aylmer Fisher was an English statistician, evolutionary biologist, and geneticist who worked on a data set that contained sepal length and width, and petal length and width from three species of iris flowers (setosa, versicolor and virginica). There were 50 flowers from each species in the data set.\n",
    "\n",
    "This dataset is available on scikit learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris(as_frame=True)\n",
    "iris_df = data.frame\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this dataframe to answer the following:\n",
    "\n",
    "(a) How many cases were included in the data?\n",
    "\n",
    "(b) How many numerical variables are included in the data? Indicate what they are, and if they\n",
    "are continuous or discrete.\n",
    "\n",
    "(c) How many categorical variables are included in\n",
    "the data, and what are they? List the corresponding levels (categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "# (a)\n",
    "num_rows = iris_df.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "numerical_values = iris_df.select_dtypes(include = 'number').columns\n",
    "print(numerical_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)', 'target'],\n",
      "      dtype='object')\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# (c)\n",
    "categorical_values = iris_df.select_dtypes(include = 'category').columns\n",
    "print(numerical_values)\n",
    "print(iris_df['target'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sampling principles (Page 22 - Section 1.3)\n",
    "\n",
    "In machine learning, we sample data in two distinct scenarios:\n",
    "\n",
    "- Dataset collection\n",
    "- Train/Val/Test split\n",
    "\n",
    "**Dataset collection**\n",
    "\n",
    "When collecting data, our goal is to obtain a representative subset of the target population to ensure that the model is trained on data that accurately reflects the real-world scenario. For instance, in developing a medical image classification model, you may need data from various hospitals, multiple doctors, and different imaging systems. The sampling strategy must align with the population of interest, which is closely tied to the specific business case.\n",
    "\n",
    "1. If the model is intended to work exclusively with Siemens X-Ray machines, the sampling can focus on data from these specific machines.\n",
    "2. If the model is designed to work with any X-ray machine, the sampling must encompass a broader range of machines from different manufacturers.\n",
    "\n",
    "The second case involves a larger and more diverse population than the first, requiring a more comprehensive sampling approach to ensure the model's generalizability across different equipment.\n",
    "\n",
    "Take a look at this paper: [ObjectNet](https://objectnet.dev), which shows how ImageNet, the most famous image classification benchmark, is in fact a biased sample ðŸ¤¯ It also introduces a new dataset with controlled variables like object orientation, background, and viewpoint, revealing that models trained on ImageNet often fail to generalize well in varied real-world conditions. This emphasizes how critical sampling strategies are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is it important to consider controlled variables like orientation, background, and viewpoint in evaluating model performance? What do these findings suggest about the limitations of benchmarks like ImageNet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "Controlled variables like orientation, background, and viewpoint are essential in evaluating model performance because they reflect real-world diversity. Without these, models may overfit to specific conditions in the training set and fail to generalize to new situations.\n",
    "\n",
    "Benchmarks like ImageNet have limitations because they often feature biased samples with ideal conditions. As shown by ObjectNet, models trained on ImageNet struggle in varied real-world conditions, suggesting the need for more diverse and realistic datasets to ensure robust model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train/Val/Test split**\n",
    "\n",
    "After collecting data, we end up with a sample that needs to be further divided into training, validation, and test sets (and potentially more subsets). This division is also a form of sampling, but it's done within the already collected sample, rather than directly from the population. The same principle applies: each subset should be representative of the entire population to ensure the model's validity. Additionally, it's crucial to ensure that these subsets are independent of each other to prevent information leakage, which could lead to biased or overly optimistic performance estimates.\n",
    "\n",
    "Andrew Ng, a renowned AI expert, published a paper in 2017 on a model for classifying chest X-rays using the ChestX-ray14 dataset. Here is the section where they describe the dataset:\n",
    "\n",
    "\"We use the ChestX-ray14 dataset released by Wang et al. (2017) which contains 112,120 frontal-view X-ray images of 30,805 unique patients. Wang et al. (2017) annotate each image with up to 14 different thoracic pathology labels using automatic extraction methods on radiology reports. We label images that have pneumonia as one of the annotated pathologies as positive examples and label all other images as negative examples for the pneumonia detection task. **We randomly split the entire dataset into 80% training, and 20% validation.**\"\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1711.05225v1\n",
    "\n",
    "What potential issues could arise from using a random split for training and validation in this context, particularly considering the number of patients and the number of images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "There are more images than patients, meaning some patients have multiple images. If we randomly split the data into training and validation sets, images from the same patient could end up in both sets. This would cause information leakage, where information from the training set is unintentionally shared with the validation set, leading to an overestimation of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Simple random sampling\n",
    "\n",
    "Let's see how we can do sampling in pandas and numpy. In pandas, getting a sample is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "94                 5.6               2.7                4.2               1.3   \n",
       "130                7.4               2.8                6.1               1.9   \n",
       "33                 5.5               4.2                1.4               0.2   \n",
       "93                 5.0               2.3                3.3               1.0   \n",
       "12                 4.8               3.0                1.4               0.1   \n",
       "126                6.2               2.8                4.8               1.8   \n",
       "59                 5.2               2.7                3.9               1.4   \n",
       "111                6.4               2.7                5.3               1.9   \n",
       "141                6.9               3.1                5.1               2.3   \n",
       "54                 6.5               2.8                4.6               1.5   \n",
       "\n",
       "     target  \n",
       "94        1  \n",
       "130       2  \n",
       "33        0  \n",
       "93        1  \n",
       "12        0  \n",
       "126       2  \n",
       "59        1  \n",
       "111       2  \n",
       "141       2  \n",
       "54        1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell a few times\n",
    "iris_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy.random.choice()` can sample only from a 1D array, therefore we can sample the indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126,  70,  96,  23,  50,  89,  14, 126,  16,  87], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = np.random.choice(iris_df.index, size=10)\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this method (by default) samples with replacement, meaning you can get one indice twice.\n",
    "\n",
    "In sampling, \"with replacement\" means that each selected element is returned to the population before the next selection, allowing it to be chosen more than once. Conversely, \"without replacement\" means that once an element is selected, it is removed from the population and cannot be chosen again.\n",
    "\n",
    "setting `replace=False` will solve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 69,  32,  15, 113,  77,  28,  13,  70,  22,   3], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = np.random.choice(iris_df.index, size=10, replace=False)\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "69                 5.6               2.5                3.9               1.1   \n",
       "32                 5.2               4.1                1.5               0.1   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "113                5.7               2.5                5.0               2.0   \n",
       "77                 6.7               3.0                5.0               1.7   \n",
       "28                 5.2               3.4                1.4               0.2   \n",
       "13                 4.3               3.0                1.1               0.1   \n",
       "70                 5.9               3.2                4.8               1.8   \n",
       "22                 4.6               3.6                1.0               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "\n",
       "     target  \n",
       "69        1  \n",
       "32        0  \n",
       "15        0  \n",
       "113       2  \n",
       "77        1  \n",
       "28        0  \n",
       "13        0  \n",
       "70        1  \n",
       "22        0  \n",
       "3         0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.loc[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[146, 137,  28, 115,  98,  93,  20,  68,  81,   1],\n",
       "       [ 12,  73,   8,  41,  84,  42,  11,  21,  99,  58],\n",
       "       [ 38,  67,  10,  23,  25,  75, 114,  45, 132, 100],\n",
       "       [  4,  44, 105, 149,  53,  97,  51, 109,  60, 119],\n",
       "       [139, 123,  85,   2,  17, 135,  77,  78, 112, 138]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can sample multiple times\n",
    "random_indices = np.random.choice(iris_df.index, size=(5, 10), replace=False)\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "however, without replacement applies within the row (ids in a row are unique) as well as from row to row (the whole array consists of unique ids), meaning we cannot repeat sampling this way more than the sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# since 20*10 = 200 is larger than the dataset size (150) we will get an error\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m random_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(iris_df\u001b[38;5;241m.\u001b[39mindex, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m10\u001b[39m), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m random_indices\n",
      "File \u001b[1;32mnumpy\\\\random\\\\mtrand.pyx:1000\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# since 20*10 = 200 is larger than the dataset size (150) we will get an error\n",
    "random_indices = np.random.choice(iris_df.index, size=(20, 10), replace=False)\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 82,  88,  33,  65,  19,  83,  69, 117, 133,  27],\n",
       "       [  9, 139,  13, 118,  70, 101,   9, 118, 123,  90],\n",
       "       [ 62, 104,  66,  33,   6,  85,  20, 125, 103,  68],\n",
       "       [ 35,  29, 104,  96,  17,  15,  43,  24, 108,  51],\n",
       "       [112, 138,   0,  23,  87, 126,  63,   2, 123,  21],\n",
       "       [ 72, 135, 110,  20,  48,  65,   3,  37,  16, 123],\n",
       "       [ 12,  82,  78, 130, 111, 121,  63,  66,   2,  81],\n",
       "       [ 22, 139,   7, 147,  73,  85,   6, 136, 107, 130],\n",
       "       [ 78, 129, 143,  81,  98, 133,   9,  45,  63,  45],\n",
       "       [  7,  30,  18,  84,  55,  55,  34,  67,  44,  90],\n",
       "       [135,  66,  92, 131,   3,  79,  20,  56,  99, 147],\n",
       "       [ 87, 116, 128,  52,  70,  86,  72,  17, 149,  48],\n",
       "       [ 97,  79,  67, 109, 140,   2,  97,  31, 142, 142],\n",
       "       [116,  26, 143,  87,   4,  27,  59,  89, 114,   1],\n",
       "       [ 52, 113,  44,  36,  88,  48,  24, 109, 111,  59],\n",
       "       [ 94,  50,  70, 111, 138, 146,  65,  72,  60,  97],\n",
       "       [ 76, 142, 113,  56, 124,  55,  55, 114, 136, 106],\n",
       "       [ 76,  47,  85, 130,  72,  84,  35,  24, 126,  72],\n",
       "       [146, 108,  80,  55,  53,  18,  21,  22,  14,  45],\n",
       "       [122,  82,  76,  49,  85,  35,  19,  63,  71,  16]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can solve this by replace=True\n",
    "# but now again some rows can have some ids more than once\n",
    "random_indices = np.random.choice(iris_df.index, size=(20, 10), replace=True)\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9, 139,  13, 118,  70, 101,   9, 118, 123,  90],\n",
       "       [ 78, 129, 143,  81,  98, 133,   9,  45,  63,  45],\n",
       "       [  7,  30,  18,  84,  55,  55,  34,  67,  44,  90],\n",
       "       [ 97,  79,  67, 109, 140,   2,  97,  31, 142, 142],\n",
       "       [ 76, 142, 113,  56, 124,  55,  55, 114, 136, 106],\n",
       "       [ 76,  47,  85, 130,  72,  84,  35,  24, 126,  72]], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which we can check as follows:\n",
    "\n",
    "def has_duplicates(row):\n",
    "    return len(row) != len(np.unique(row))\n",
    "\n",
    "rows_with_duplicates = np.array([row for row in random_indices if has_duplicates(row)])\n",
    "rows_with_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95,  20,  13,  85,  72,  46,  52,  99, 141, 149],\n",
       "       [104,  75,  74, 122, 110,  77,  55,  70, 126,  54],\n",
       "       [ 67,  58,  85, 102,  65, 136,  61, 133, 132,  55],\n",
       "       [ 38, 134,  85,  76,  86,  25,  88,  73, 147,  48],\n",
       "       [109, 128, 147,  50, 149,   5,  61, 124, 138,  84],\n",
       "       [140,  24,   5, 109, 139,  31, 104, 105,  41,  92],\n",
       "       [ 46,  95,  99, 108,  74,  42, 126, 131,  40, 119],\n",
       "       [ 46,  89, 109, 137, 100,  10, 108,  28,  95,  96],\n",
       "       [138, 118,  26,  10, 110,  37, 104,   5,   2, 149],\n",
       "       [132,  91, 140, 128,  49,  82,  16, 109, 146,  71],\n",
       "       [146, 112,   7,  75, 134, 127,  54,  25,  15,  90],\n",
       "       [ 43,  83,  23, 137,   0,  87,  80,  37,  94,   4],\n",
       "       [ 84,  67, 104,  47, 132, 113, 103, 149, 100, 139],\n",
       "       [106, 140, 133,  33, 112,  65,  75,  10,  59, 118],\n",
       "       [137,   6, 130, 143,  37,  58,  51,   7, 118, 135],\n",
       "       [110,   2,  39,  14, 126, 101, 128,  32, 125, 130],\n",
       "       [ 40,  58, 113,  64,  62,  41,  17,  71,  13,   8],\n",
       "       [ 92,   3, 102,   6,   9, 133,  68,  76,  85, 131],\n",
       "       [ 68,  12, 100, 126, 115,   1, 135,  73, 138,  57],\n",
       "       [ 33,  22,  70,  76,  37,  21, 133,  97, 123, 108]], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can solve this with a for loop\n",
    "# Inside every row we have unique ids\n",
    "# But from row to row ids can repeat\n",
    "random_indices = np.array([np.random.choice(iris_df.index, size=10, replace=False) for _ in range(20)])\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no duplicates in any row:\n",
    "rows_with_duplicates = np.array([row for row in random_indices if has_duplicates(row)])\n",
    "rows_with_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit learn let's you do stratified sampling when splitting a dataset. Let's see why it is important, with randomly generated data.\n",
    "\n",
    "Imagine a binary classification problem with 50 samples, each having 5 features. The positive class has a prevalence of 10%, meaning that 10% of the samples are labeled as positive (class 1), while the remaining 90% are labeled as negative (class 0). The dataset is generated with random features and class labels according to the specified proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "n_features = 5\n",
    "positive_class_proportion = 0.1\n",
    "negative_class_proportion = 1 - positive_class_proportion\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = np.random.choice([0, 1], size=n_samples, p=[negative_class_proportion, positive_class_proportion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22\n"
     ]
    }
   ],
   "source": [
    "# Note: The actual proportion of the positive class may not be exactly 0.2 due to the randomness in sampling,\n",
    "# but it will approximate this value. To check, we can calculate the proportion of positive samples in 'y'.\n",
    "p_y = np.sum(y) / n_samples\n",
    "print(p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# If you prefer a method that ensures the correct proportion\n",
    "# The choice depends on the simulation you would like to make\n",
    "number_of_ones = int(positive_class_proportion * 50)\n",
    "number_of_zeros = n_samples - number_of_ones\n",
    "y = np.concatenate((np.ones(number_of_ones), np.zeros(number_of_zeros)))\n",
    "p_y = np.sum(y) / n_samples\n",
    "print(p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class proportion in training set: 0.11\n",
      "Positive class proportion in test set: 0.08\n",
      "Positive class proportion in before split: 0.10\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL MULTIPLE TIMES\n",
    "# let's first split with simple random sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "p_train = np.sum(y_train)/len(y_train)\n",
    "p_test = np.sum(y_test)/len(y_test)\n",
    "\n",
    "print(f\"Positive class proportion in training set: {p_train:.2f}\")\n",
    "print(f\"Positive class proportion in test set: {p_test:.2f}\")\n",
    "print(f\"Positive class proportion in before split: {p_y:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the cell above multiple times, you may notice that the proportions of the positive class in the training and test sets can vary significantly across different splits. This variability occurs because the simple random sampling method does not control for class proportions.\n",
    "\n",
    "We can use stratification and solve this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class proportion in training set: 0.11\n",
      "Positive class proportion in test set: 0.08\n",
      "Positive class proportion in before split: 0.10\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL MULTIPLE TIMES\n",
    "# You will see that the proportions are always close to the positive_class_proportion\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "p_train = np.sum(y_train)/len(y_train)\n",
    "p_test = np.sum(y_test)/len(y_test)\n",
    "\n",
    "print(f\"Positive class proportion in training set: {p_train:.2f}\")\n",
    "print(f\"Positive class proportion in test set: {p_test:.2f}\")\n",
    "print(f\"Positive class proportion in before split: {p_y:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "banijay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
